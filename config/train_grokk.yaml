defaults:
  - dataset: mod_division_dataset
  - model: gpt2_meta
  - _self_

dataset:
  frac_train: 0.4
  p: 96

# model config will be loaded from defaults

train:
  num_workers: 0
  bsize: 512
  lr: 0.001
  weight_decay: 1.0
  betas: [0.9, 0.98]
  warmup_steps: 10
  eval_every: 100
  eval_batches: 8
  max_steps: 4000
  grokfast_alpha: 0.98
  grokfast_lamb: 2.0

wandb:
  use_wandb: true
  wandb_project: grokking_replica
